#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
GPUè®­ç»ƒåŠŸèƒ½æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯ä¿®å¤åçš„GPUè®­ç»ƒåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path

def test_basic_gpu():
    """æµ‹è¯•åŸºæœ¬GPUåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•åŸºæœ¬GPUåŠŸèƒ½...")
    
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨")
        return False
    
    device = torch.device('cuda')
    print(f"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
    
    # æµ‹è¯•å¼ é‡è¿ç®—
    x = torch.randn(1000, 1000).to(device)
    y = torch.randn(1000, 1000).to(device)
    z = torch.matmul(x, y)
    
    print("âœ… GPUå¼ é‡è¿ç®—æ­£å¸¸")
    
    # æ¸…ç†å†…å­˜
    del x, y, z
    torch.cuda.empty_cache()
    
    return True

def test_mixed_precision():
    """æµ‹è¯•æ··åˆç²¾åº¦è®­ç»ƒ"""
    print("ğŸ§ª æµ‹è¯•æ··åˆç²¾åº¦è®­ç»ƒ...")
    
    try:
        from torch.cuda.amp import GradScaler, autocast
        
        device = torch.device('cuda')
        scaler = GradScaler()
        
        # åˆ›å»ºç®€å•æ¨¡å‹
        model = torch.nn.Linear(100, 50).to(device)
        optimizer = torch.optim.Adam(model.parameters())
        criterion = torch.nn.MSELoss()
        
        # æµ‹è¯•æ··åˆç²¾åº¦è®­ç»ƒæ­¥éª¤
        x = torch.randn(32, 100).to(device)
        y = torch.randn(32, 50).to(device)
        
        optimizer.zero_grad()
        
        with autocast():
            output = model(x)
            loss = criterion(output, y)
        
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        
        print("âœ… æ··åˆç²¾åº¦è®­ç»ƒæ­£å¸¸")
        
        # æ¸…ç†
        del model, optimizer, criterion, x, y, output, loss
        torch.cuda.empty_cache()
        
        return True
        
    except Exception as e:
        print(f"âŒ æ··åˆç²¾åº¦æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_compilation():
    """æµ‹è¯•æ¨¡å‹ç¼–è¯‘"""
    print("ğŸ§ª æµ‹è¯•æ¨¡å‹ç¼–è¯‘...")
    
    try:
        if not hasattr(torch, 'compile'):
            print("â„¹ï¸ æ¨¡å‹ç¼–è¯‘åŠŸèƒ½ä¸å¯ç”¨ï¼ˆéœ€è¦PyTorch 2.0+ï¼‰")
            return True
        
        device = torch.device('cuda')
        
        # åˆ›å»ºç®€å•æ¨¡å‹
        model = torch.nn.Sequential(
            torch.nn.Linear(100, 50),
            torch.nn.ReLU(),
            torch.nn.Linear(50, 10)
        ).to(device)
        
        # ç¼–è¯‘æ¨¡å‹
        compiled_model = torch.compile(model)
        
        # æµ‹è¯•ç¼–è¯‘åçš„æ¨¡å‹
        x = torch.randn(32, 100).to(device)
        output = compiled_model(x)
        
        print("âœ… æ¨¡å‹ç¼–è¯‘æ­£å¸¸")
        
        # æ¸…ç†
        del model, compiled_model, x, output
        torch.cuda.empty_cache()
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹ç¼–è¯‘æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_data_loading():
    """æµ‹è¯•GPUä¼˜åŒ–çš„æ•°æ®åŠ è½½"""
    print("ğŸ§ª æµ‹è¯•GPUä¼˜åŒ–çš„æ•°æ®åŠ è½½...")
    
    try:
        from torch.utils.data import Dataset, DataLoader
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
        class TestDataset(Dataset):
            def __init__(self, size=1000):
                self.data = torch.randn(size, 100)
                self.labels = torch.randint(0, 4, (size,))
            
            def __len__(self):
                return len(self.data)
            
            def __getitem__(self, idx):
                return self.data[idx], self.labels[idx]
        
        dataset = TestDataset()
        
        # æµ‹è¯•GPUä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨
        dataloader = DataLoader(
            dataset,
            batch_size=32,
            shuffle=True,
            num_workers=2,
            pin_memory=True,
            persistent_workers=True,
            prefetch_factor=2
        )
        
        device = torch.device('cuda')
        
        # æµ‹è¯•æ•°æ®ä¼ è¾“
        for batch_data, batch_labels in dataloader:
            batch_data = batch_data.to(device, non_blocking=True)
            batch_labels = batch_labels.to(device, non_blocking=True)
            
            # ç®€å•è®¡ç®—
            result = torch.sum(batch_data)
            
            break  # åªæµ‹è¯•ä¸€ä¸ªbatch
        
        print("âœ… GPUä¼˜åŒ–çš„æ•°æ®åŠ è½½æ­£å¸¸")
        
        # æ¸…ç†
        del dataset, dataloader, batch_data, batch_labels, result
        torch.cuda.empty_cache()
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_multi_gpu():
    """æµ‹è¯•å¤šGPUæ”¯æŒ"""
    print("ğŸ§ª æµ‹è¯•å¤šGPUæ”¯æŒ...")
    
    if torch.cuda.device_count() < 2:
        print("â„¹ï¸ åªæœ‰ä¸€ä¸ªGPUï¼Œè·³è¿‡å¤šGPUæµ‹è¯•")
        return True
    
    try:
        device = torch.device('cuda')
        
        # åˆ›å»ºæ¨¡å‹
        model = torch.nn.Linear(100, 50).to(device)
        
        # ä½¿ç”¨DataParallel
        if torch.cuda.device_count() > 1:
            model = torch.nn.DataParallel(model)
            print(f"âœ… å¤šGPUæ”¯æŒæ­£å¸¸: {torch.cuda.device_count()} ä¸ªGPU")
        else:
            print("â„¹ï¸ åªæœ‰ä¸€ä¸ªGPUï¼Œæ— æ³•æµ‹è¯•å¤šGPU")
        
        # æ¸…ç†
        del model
        torch.cuda.empty_cache()
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤šGPUæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("="*60)
    print("GPUè®­ç»ƒåŠŸèƒ½æµ‹è¯•")
    print("="*60)
    
    tests = [
        test_basic_gpu,
        test_mixed_precision,
        test_model_compilation,
        test_data_loading,
        test_multi_gpu
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        print()
    
    print("="*60)
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰GPUåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥GPUç¯å¢ƒ")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
