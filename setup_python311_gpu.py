#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Python 3.11 GPUè®­ç»ƒç¯å¢ƒè®¾ç½®
ä½¿ç”¨condaæˆ–ç›´æ¥å®‰è£…PyTorch GPUç‰ˆæœ¬
"""

import os
import sys
import subprocess
import json

def create_conda_environment():
    """åˆ›å»ºcondaç¯å¢ƒ"""
    print("ğŸ åˆ›å»ºPython 3.11 condaç¯å¢ƒ...")
    
    # å°è¯•ä¸åŒçš„condaè·¯å¾„
    conda_paths = [
        "conda",
        "G:\\anaconda3\\Scripts\\conda.exe",
        "C:\\Users\\tsawke\\anaconda3\\Scripts\\conda.exe",
        "C:\\ProgramData\\Anaconda3\\Scripts\\conda.exe"
    ]
    
    for conda_path in conda_paths:
        try:
            print(f"å°è¯•ä½¿ç”¨: {conda_path}")
            result = subprocess.run([
                conda_path, "create", "-n", "swallow-gpu", "python=3.11", "-y"
            ], capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                print("âœ… condaç¯å¢ƒåˆ›å»ºæˆåŠŸ")
                return conda_path
            else:
                print(f"âŒ å¤±è´¥: {result.stderr}")
        except (subprocess.TimeoutExpired, FileNotFoundError, Exception) as e:
            print(f"âŒ å¼‚å¸¸: {e}")
    
    return None

def install_pytorch_gpu(conda_path):
    """å®‰è£…PyTorch GPUç‰ˆæœ¬"""
    print("\nğŸ“¦ å®‰è£…PyTorch GPUç‰ˆæœ¬...")
    
    # æ¿€æ´»ç¯å¢ƒå¹¶å®‰è£…PyTorch
    install_commands = [
        [conda_path, "install", "-n", "swallow-gpu", "-c", "pytorch", "-c", "nvidia", "pytorch", "torchvision", "torchaudio", "pytorch-cuda=12.1", "-y"],
        [conda_path, "install", "-n", "swallow-gpu", "-c", "pytorch", "-c", "nvidia", "pytorch", "torchvision", "torchaudio", "pytorch-cuda=11.8", "-y"],
        [conda_path, "run", "-n", "swallow-gpu", "pip", "install", "torch", "torchvision", "torchaudio", "--index-url", "https://download.pytorch.org/whl/cu121"]
    ]
    
    for cmd in install_commands:
        try:
            print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
            
            if result.returncode == 0:
                print("âœ… PyTorchå®‰è£…æˆåŠŸ")
                return True
            else:
                print(f"âŒ å¤±è´¥: {result.stderr}")
        except subprocess.TimeoutExpired:
            print("â° å®‰è£…è¶…æ—¶")
        except Exception as e:
            print(f"âŒ å¼‚å¸¸: {e}")
    
    return False

def install_other_dependencies(conda_path):
    """å®‰è£…å…¶ä»–ä¾èµ–"""
    print("\nğŸ“¦ å®‰è£…å…¶ä»–ä¾èµ–...")
    
    dependencies = [
        "numpy", "pandas", "matplotlib", "scipy", "scikit-learn", 
        "seaborn", "tqdm", "jupyter", "ipykernel"
    ]
    
    for dep in dependencies:
        try:
            cmd = [conda_path, "install", "-n", "swallow-gpu", dep, "-y"]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                print(f"âœ… {dep} å®‰è£…æˆåŠŸ")
            else:
                print(f"âš ï¸ {dep} å®‰è£…å¤±è´¥ï¼Œå°è¯•pipå®‰è£…")
                # å°è¯•pipå®‰è£…
                pip_cmd = [conda_path, "run", "-n", "swallow-gpu", "pip", "install", dep]
                subprocess.run(pip_cmd, capture_output=True, text=True, timeout=300)
        except Exception as e:
            print(f"âš ï¸ {dep} å®‰è£…å¼‚å¸¸: {e}")

def test_gpu_functionality(conda_path):
    """æµ‹è¯•GPUåŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•GPUåŠŸèƒ½...")
    
    test_script = """
import torch
print(f'PyTorchç‰ˆæœ¬: {torch.__version__}')
print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')

if torch.cuda.is_available():
    print(f'CUDAç‰ˆæœ¬: {torch.version.cuda}')
    print(f'GPUæ•°é‡: {torch.cuda.device_count()}')
    print(f'GPUåç§°: {torch.cuda.get_device_name(0)}')
    
    # æµ‹è¯•GPUè®¡ç®—
    try:
        x = torch.randn(100, 100).cuda()
        y = torch.randn(100, 100).cuda()
        z = torch.matmul(x, y)
        print('âœ… GPUè®¡ç®—æµ‹è¯•æˆåŠŸ')
    except Exception as e:
        print(f'âŒ GPUè®¡ç®—æµ‹è¯•å¤±è´¥: {e}')
else:
    print('âŒ CUDAä¸å¯ç”¨')
"""
    
    try:
        cmd = [conda_path, "run", "-n", "swallow-gpu", "python", "-c", test_script]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
        
        if result.returncode == 0:
            print(result.stdout)
            return True
        else:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {result.stderr}")
            return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        return False

def create_gpu_config():
    """åˆ›å»ºGPUé…ç½®æ–‡ä»¶"""
    config = {
        "data_dir": "./hyx_data",
        "batch_size": 32,
        "learning_rate": 1e-4,
        "num_epochs": 100,
        "patience": 15,
        "k_folds": 5,
        "test_size": 0.2,
        "model_types": ["cnn", "transformer", "fusion"],
        "use_class_weights": True,
        "augmentation": True,
        "feature_types": ["stft", "time_series"],
        "use_gpu": True,
        "device_id": 0,
        "use_amp": True,
        "compile_model": True,
        "multi_gpu": False,
        "device_count": 1,
        "dataloader_params": {
            "num_workers": 8,
            "pin_memory": True,
            "persistent_workers": True,
            "prefetch_factor": 4,
            "drop_last": True
        }
    }
    
    with open("python311_gpu_config.json", "w", encoding="utf-8") as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    
    print("âœ… Python 3.11 GPUé…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ")

def create_run_script(conda_path):
    """åˆ›å»ºè¿è¡Œè„šæœ¬"""
    script_content = f'''#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Python 3.11 GPUè®­ç»ƒè¿è¡Œè„šæœ¬
"""

import subprocess
import sys
import os

def main():
    print("ğŸš€ Python 3.11 GPUè®­ç»ƒ")
    print("="*50)
    
    # ä½¿ç”¨condaç¯å¢ƒè¿è¡Œè®­ç»ƒ
    cmd = [
        "{conda_path}", "run", "-n", "swallow-gpu", "python",
        "run_behavior_classification.py",
        "--full-pipeline",
        "--config", "python311_gpu_config.json",
        "--mixed-precision",
        "--batch-size", "32"
    ]
    
    print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    
    try:
        result = subprocess.run(cmd, check=True)
        print("âœ… è®­ç»ƒå®Œæˆ")
    except subprocess.CalledProcessError as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
    except Exception as e:
        print(f"âŒ å¼‚å¸¸: {e}")

if __name__ == "__main__":
    main()
'''
    
    with open("run_python311_training.py", "w", encoding="utf-8") as f:
        f.write(script_content)
    
    print("âœ… Python 3.11è®­ç»ƒè„šæœ¬åˆ›å»ºå®Œæˆ")

def main():
    print("="*60)
    print("Python 3.11 GPUè®­ç»ƒç¯å¢ƒè®¾ç½®")
    print("="*60)
    
    # åˆ›å»ºcondaç¯å¢ƒ
    conda_path = create_conda_environment()
    
    if conda_path:
        # å®‰è£…PyTorch
        if install_pytorch_gpu(conda_path):
            # å®‰è£…å…¶ä»–ä¾èµ–
            install_other_dependencies(conda_path)
            
            # æµ‹è¯•GPUåŠŸèƒ½
            if test_gpu_functionality(conda_path):
                print("\nğŸ‰ Python 3.11 GPUè®­ç»ƒç¯å¢ƒé…ç½®æˆåŠŸï¼")
                
                # åˆ›å»ºé…ç½®æ–‡ä»¶
                create_gpu_config()
                
                # åˆ›å»ºè¿è¡Œè„šæœ¬
                create_run_script(conda_path)
                
                print("\nğŸ“‹ ä½¿ç”¨æ–¹æ³•:")
                print("1. æ¿€æ´»ç¯å¢ƒ: conda activate swallow-gpu")
                print("2. è¿è¡Œè®­ç»ƒ: python run_python311_training.py")
                print("3. æˆ–ç›´æ¥è¿è¡Œ: conda run -n swallow-gpu python run_behavior_classification.py --full-pipeline --config python311_gpu_config.json --mixed-precision")
                
                return True
            else:
                print("\nâš ï¸ PyTorchå®‰è£…æˆåŠŸä½†GPUä¸å¯ç”¨")
        else:
            print("\nâŒ PyTorchå®‰è£…å¤±è´¥")
    else:
        print("\nâŒ condaç¯å¢ƒåˆ›å»ºå¤±è´¥")
    
    print("\nğŸ’¡ æ›¿ä»£æ–¹æ¡ˆ:")
    print("1. æ‰‹åŠ¨å®‰è£…Python 3.11")
    print("2. ä½¿ç”¨Dockerç¯å¢ƒ")
    print("3. ä½¿ç”¨äº‘ç«¯GPUæœåŠ¡")
    
    return False

if __name__ == "__main__":
    main()
