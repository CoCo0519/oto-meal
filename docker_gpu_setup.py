#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Docker GPUè®­ç»ƒç¯å¢ƒè®¾ç½®è„šæœ¬
åˆ›å»ºä¸€ä¸ªåŒ…å«GPUæ”¯æŒçš„Dockerç¯å¢ƒæ¥è¿è¡Œè®­ç»ƒ
"""

import os
import subprocess
import sys

def create_dockerfile():
    """åˆ›å»ºDockerfile"""
    dockerfile_content = """
# ä½¿ç”¨å®˜æ–¹PyTorché•œåƒï¼ŒåŒ…å«CUDAæ”¯æŒ
FROM pytorch/pytorch:2.7.0-cuda12.1-cudnn8-devel

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…å¿…è¦çš„PythonåŒ…
RUN pip install --no-cache-dir \\
    numpy pandas matplotlib seaborn \\
    scikit-learn tqdm \\
    jupyter notebook

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
COPY . /app/

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV CUDA_VISIBLE_DEVICES=0

# æš´éœ²ç«¯å£ï¼ˆå¦‚æœéœ€è¦Jupyterï¼‰
EXPOSE 8888

# é»˜è®¤å‘½ä»¤
CMD ["python", "run_behavior_classification.py", "--full-pipeline"]
"""
    
    with open("Dockerfile", "w", encoding="utf-8") as f:
        f.write(dockerfile_content)
    print("âœ… Dockerfile åˆ›å»ºå®Œæˆ")

def create_docker_compose():
    """åˆ›å»ºdocker-compose.yml"""
    compose_content = """
version: '3.8'

services:
  gpu-training:
    build: .
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - .:/app
      - ./results:/app/results
    command: python run_behavior_classification.py --full-pipeline --mixed-precision --batch-size 32
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
"""
    
    with open("docker-compose.yml", "w", encoding="utf-8") as f:
        f.write(compose_content)
    print("âœ… docker-compose.yml åˆ›å»ºå®Œæˆ")

def create_gpu_config():
    """åˆ›å»ºGPUè®­ç»ƒé…ç½®"""
    config_content = """{
  "data_dir": "./hyx_data",
  "batch_size": 32,
  "learning_rate": 1e-4,
  "num_epochs": 100,
  "patience": 15,
  "k_folds": 5,
  "test_size": 0.2,
  "model_types": ["cnn", "transformer", "fusion"],
  "use_class_weights": true,
  "augmentation": true,
  "feature_types": ["stft", "time_series"],
  "use_gpu": true,
  "device_id": 0,
  "use_amp": true,
  "compile_model": true,
  "multi_gpu": false,
  "device_count": 1,
  "dataloader_params": {
    "num_workers": 8,
    "pin_memory": true,
    "persistent_workers": true,
    "prefetch_factor": 4,
    "drop_last": true
  }
}"""
    
    with open("gpu_config.json", "w", encoding="utf-8") as f:
        f.write(config_content)
    print("âœ… GPUé…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ")

def create_run_script():
    """åˆ›å»ºè¿è¡Œè„šæœ¬"""
    run_script_content = """#!/bin/bash
# GPUè®­ç»ƒè¿è¡Œè„šæœ¬

echo "ğŸš€ å¯åŠ¨GPUè®­ç»ƒç¯å¢ƒ..."

# æ£€æŸ¥Dockeræ˜¯å¦å®‰è£…
if ! command -v docker &> /dev/null; then
    echo "âŒ Dockeræœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Docker Desktop"
    exit 1
fi

# æ£€æŸ¥NVIDIA Dockeræ”¯æŒ
if ! docker run --rm --gpus all nvidia/cuda:12.1-base-ubuntu20.04 nvidia-smi &> /dev/null; then
    echo "âŒ NVIDIA Dockeræ”¯æŒæœªé…ç½®ï¼Œè¯·å®‰è£…nvidia-docker2"
    exit 1
fi

# æ„å»ºDockeré•œåƒ
echo "ğŸ“¦ æ„å»ºDockeré•œåƒ..."
docker build -t swallow-gpu-training .

# è¿è¡ŒGPUè®­ç»ƒ
echo "ğŸ¯ å¼€å§‹GPUè®­ç»ƒ..."
docker run --rm --gpus all \\
    -v $(pwd):/app \\
    -v $(pwd)/results:/app/results \\
    swallow-gpu-training \\
    python run_behavior_classification.py \\
    --full-pipeline \\
    --config gpu_config.json \\
    --mixed-precision \\
    --batch-size 32

echo "âœ… GPUè®­ç»ƒå®Œæˆï¼"
"""
    
    with open("run_gpu_training.sh", "w", encoding="utf-8") as f:
        f.write(run_script_content)
    
    # åœ¨Windowsä¸Šåˆ›å»ºæ‰¹å¤„ç†æ–‡ä»¶
    bat_content = """@echo off
echo ğŸš€ å¯åŠ¨GPUè®­ç»ƒç¯å¢ƒ...

REM æ£€æŸ¥Dockeræ˜¯å¦å®‰è£…
docker --version >nul 2>&1
if errorlevel 1 (
    echo âŒ Dockeræœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Docker Desktop
    pause
    exit /b 1
)

REM æ„å»ºDockeré•œåƒ
echo ğŸ“¦ æ„å»ºDockeré•œåƒ...
docker build -t swallow-gpu-training .

REM è¿è¡ŒGPUè®­ç»ƒ
echo ğŸ¯ å¼€å§‹GPUè®­ç»ƒ...
docker run --rm --gpus all ^
    -v %cd%:/app ^
    -v %cd%/results:/app/results ^
    swallow-gpu-training ^
    python run_behavior_classification.py ^
    --full-pipeline ^
    --config gpu_config.json ^
    --mixed-precision ^
    --batch-size 32

echo âœ… GPUè®­ç»ƒå®Œæˆï¼
pause
"""
    
    with open("run_gpu_training.bat", "w", encoding="utf-8") as f:
        f.write(bat_content)
    
    print("âœ… è¿è¡Œè„šæœ¬åˆ›å»ºå®Œæˆ")

def main():
    print("="*60)
    print("Docker GPUè®­ç»ƒç¯å¢ƒè®¾ç½®")
    print("="*60)
    
    print("æ­£åœ¨åˆ›å»ºDockeré…ç½®æ–‡ä»¶...")
    create_dockerfile()
    create_docker_compose()
    create_gpu_config()
    create_run_script()
    
    print("\n" + "="*60)
    print("ğŸ‰ Docker GPUç¯å¢ƒè®¾ç½®å®Œæˆï¼")
    print("="*60)
    
    print("\nğŸ“‹ ä½¿ç”¨æ­¥éª¤ï¼š")
    print("1. å®‰è£…Docker Desktop")
    print("2. å®‰è£…NVIDIA Container Toolkit")
    print("3. è¿è¡Œ: run_gpu_training.bat")
    
    print("\nğŸ”§ æ‰‹åŠ¨è¿è¡Œå‘½ä»¤ï¼š")
    print("docker build -t swallow-gpu-training .")
    print("docker run --rm --gpus all -v %cd%:/app swallow-gpu-training python run_behavior_classification.py --full-pipeline --mixed-precision")
    
    print("\nğŸ“ åˆ›å»ºçš„æ–‡ä»¶ï¼š")
    print("- Dockerfile")
    print("- docker-compose.yml") 
    print("- gpu_config.json")
    print("- run_gpu_training.bat")
    print("- run_gpu_training.sh")

if __name__ == "__main__":
    main()

