# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„è®­ç»ƒå’Œè¯„ä¼°æµæ°´çº¿
æ•´åˆæ•°æ®æ ‡æ³¨ã€ç‰¹å¾æå–ã€æ¨¡å‹è®­ç»ƒã€è¯„ä¼°å’Œæ¨ç†çš„å®Œæ•´å·¥ä½œæµ

åŠŸèƒ½æ¨¡å—ï¼š
1. æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
2. ç‰¹å¾æå–ï¼ˆSTFT + MFCC + æ—¶é—´åºåˆ—ï¼‰
3. æ¨¡å‹è®­ç»ƒï¼ˆCNN + Transformer + èåˆæ¨¡å‹ï¼‰
4. æ¨¡å‹è¯„ä¼°å’Œå¯è§†åŒ–
5. æ¨¡å‹æ¨ç†å’Œéƒ¨ç½²

ä½œè€…ï¼šåŸºäºProject-Swallowé¡¹ç›®æ‰©å±•
"""

import os
import sys
import argparse
import json
import pickle
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix, f1_score
from sklearn.preprocessing import StandardScaler, LabelEncoder

try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
    from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
except ImportError:
    print("âš ï¸ PyTorch æœªå®‰è£…ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
    TORCH_AVAILABLE = False
    # åˆ›å»ºå ä½ç¬¦ç±»
    class Dataset:
        pass
    class DataLoader:
        pass
    class WeightedRandomSampler:
        pass
    class nn:
        class Module:
            pass
        class Linear:
            pass
        class Conv1d:
            pass
        class BatchNorm1d:
            pass
        class Dropout:
            pass
        class ReLU:
            pass
        class MaxPool1d:
            pass
        class AdaptiveAvgPool1d:
            pass
        class TransformerEncoder:
            pass
        class TransformerEncoderLayer:
            pass
        class LayerNorm:
            pass
        class MultiheadAttention:
            pass
        class Sequential:
            pass
    class optim:
        class Adam:
            def __init__(self, *args, **kwargs):
                pass
        class SGD:
            def __init__(self, *args, **kwargs):
                pass
    class CosineAnnealingLR:
        def __init__(self, *args, **kwargs):
            pass
    class ReduceLROnPlateau:
        def __init__(self, *args, **kwargs):
            pass
    class F:
        @staticmethod
        def relu(x):
            return x
        @staticmethod
        def max_pool1d(x, kernel_size):
            return x
        @staticmethod
        def adaptive_avg_pool1d(x, output_size):
            return x

from tqdm import tqdm
import logging

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from data_labeling_system import DataLabeler, BehaviorDetector
from behavior_classification_system import FeatureExtractor, BehaviorClassificationConfig
from advanced_models import (
    AdvancedBehaviorCNN, BehaviorTransformer, MultiModalFusionModel,
    BehaviorClassificationLoss, create_model, model_summary
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class MultiModalDataset(Dataset):
    """å¤šæ¨¡æ€æ•°æ®é›†ï¼šæ”¯æŒSTFTç‰¹å¾å’Œæ—¶é—´åºåˆ—æ•°æ®"""
    
    def __init__(self, stft_features, time_series_data, labels, transform=None):
        self.stft_features = torch.FloatTensor(stft_features)
        self.time_series_data = torch.FloatTensor(time_series_data)
        self.labels = torch.LongTensor(labels)
        self.transform = transform
        
    def __len__(self):
        return len(self.labels)
    
    def __getitem__(self, idx):
        stft = self.stft_features[idx]
        time_series = self.time_series_data[idx]
        label = self.labels[idx]
        
        if self.transform:
            stft = self.transform(stft)
            
        return stft, time_series, label

class EarlyStopping:
    """æ—©åœæœºåˆ¶"""
    
    def __init__(self, patience=10, min_delta=0.001, restore_best_weights=True):
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_score = None
        self.counter = 0
        self.best_weights = None
        
    def __call__(self, score, model):
        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(model)
        elif score < self.best_score + self.min_delta:
            self.counter += 1
            if self.counter >= self.patience:
                if self.restore_best_weights:
                    model.load_state_dict(self.best_weights)
                return True
        else:
            self.best_score = score
            self.counter = 0
            self.save_checkpoint(model)
        return False
    
    def save_checkpoint(self, model):
        self.best_weights = model.state_dict().copy()

class TrainingPipeline:
    """å®Œæ•´çš„è®­ç»ƒæµæ°´çº¿"""
    
    def __init__(self, config_path: Optional[str] = None):
        self.config = self._load_config(config_path)
        
        # æ™ºèƒ½è®¾å¤‡é€‰æ‹©
        self.device = self._setup_device()
        self.feature_extractor = FeatureExtractor()
        self.scaler_stft = StandardScaler()
        self.scaler_time_series = StandardScaler()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = f"training_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.makedirs(self.output_dir, exist_ok=True)
        
        logger.info(f"è®­ç»ƒæµæ°´çº¿åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
        logger.info(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        
        # åˆå§‹åŒ–æ··åˆç²¾åº¦è®­ç»ƒ
        self.scaler = None
        if self.config.get('use_amp', False) and torch.cuda.is_available():
            try:
                from torch.cuda.amp import GradScaler
                self.scaler = GradScaler()
                logger.info("âœ… è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒå·²å¯ç”¨")
            except ImportError:
                logger.warning("âš ï¸ æ— æ³•å¯¼å…¥GradScalerï¼Œç¦ç”¨æ··åˆç²¾åº¦è®­ç»ƒ")
                self.config['use_amp'] = False
    
    def _setup_device(self):
        """æ™ºèƒ½è®¾å¤‡è®¾ç½®"""
        if not torch.cuda.is_available():
            return torch.device('cpu')
        
        # æ£€æŸ¥æ˜¯å¦æŒ‡å®šäº†GPUè®¾å¤‡
        device_id = self.config.get('device_id', 0)
        
        # æ£€æŸ¥CUDA_VISIBLE_DEVICESç¯å¢ƒå˜é‡
        if 'CUDA_VISIBLE_DEVICES' in os.environ:
            visible_devices = os.environ['CUDA_VISIBLE_DEVICES']
            if visible_devices:
                device_id = int(visible_devices.split(',')[0])
        
        # è®¾ç½®è®¾å¤‡
        device = torch.device(f'cuda:{device_id}')
        torch.cuda.set_device(device_id)
        
        # åº”ç”¨GPUä¼˜åŒ–è®¾ç½®
        if self.config.get('use_gpu', True):
            torch.backends.cudnn.benchmark = True
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            
            if hasattr(torch, "set_float32_matmul_precision"):
                torch.set_float32_matmul_precision("high")
        
        return device
    
    def _load_config(self, config_path: Optional[str]) -> Dict:
        """åŠ è½½é…ç½®"""
        default_config = {
            'data_dir': './hyx_data',
            'batch_size': 32,
            'learning_rate': 1e-4,
            'num_epochs': 100,
            'patience': 15,
            'k_folds': 5,
            'test_size': 0.2,
            'model_types': ['cnn', 'transformer', 'fusion'],
            'use_class_weights': True,
            'augmentation': True,
            'feature_types': ['stft', 'time_series'],
            'use_gpu': True,
            'device_id': 0,
            'use_amp': False,
            'compile_model': False,
            'multi_gpu': False,
            'device_count': 1,
            'dataloader_params': {
                'num_workers': 4,
                'pin_memory': True,
                'persistent_workers': True,
                'prefetch_factor': 2,
                'drop_last': False
            }
        }
        
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = json.load(f)
            default_config.update(user_config)
            
        return default_config
    
    def prepare_data(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """æ•°æ®å‡†å¤‡ï¼šæ ‡æ³¨ + ç‰¹å¾æå–"""
        logger.info("å¼€å§‹æ•°æ®å‡†å¤‡é˜¶æ®µ...")
        
        # 1. æ•°æ®æ ‡æ³¨
        labeler = DataLabeler(self.config['data_dir'])
        labeled_data = labeler.create_labeled_dataset()
        
        if not labeled_data:
            raise ValueError("æœªæ‰¾åˆ°å¯ç”¨çš„æ ‡æ³¨æ•°æ®")
        
        # ä¿å­˜æ ‡æ³¨æ•°æ®
        labeled_file = os.path.join(self.output_dir, 'labeled_dataset.npz')
        labeler.save_labeled_dataset(labeled_data, labeled_file)
        
        # 2. ç‰¹å¾æå–
        logger.info("å¼€å§‹ç‰¹å¾æå–...")
        
        all_stft_features = []
        all_time_series = []
        all_labels = []
        
        for sample in tqdm(labeled_data, desc="ç‰¹å¾æå–"):
            ear_data = sample['ear_data']
            labels = sample['labels']
            
            # åˆ›å»ºæ»‘åŠ¨çª—å£
            windows, window_labels = self._create_sliding_windows(ear_data, labels)
            
            for window_data, window_label in zip(windows, window_labels):
                # STFTç‰¹å¾
                stft_feat = self.feature_extractor.extract_stft_features(window_data)
                all_stft_features.append(stft_feat)
                
                # æ—¶é—´åºåˆ—æ•°æ®ï¼ˆåŸå§‹ä¿¡å·ï¼‰
                all_time_series.append(window_data)
                all_labels.append(window_label)
        
        stft_features = np.array(all_stft_features)
        time_series_data = np.array(all_time_series)
        labels = np.array(all_labels)
        
        logger.info(f"ç‰¹å¾æå–å®Œæˆ:")
        logger.info(f"  STFTç‰¹å¾å½¢çŠ¶: {stft_features.shape}")
        logger.info(f"  æ—¶é—´åºåˆ—å½¢çŠ¶: {time_series_data.shape}")
        logger.info(f"  æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(labels)}")
        
        # 3. ç‰¹å¾æ ‡å‡†åŒ–
        # é‡å¡‘STFTç‰¹å¾ç”¨äºæ ‡å‡†åŒ–
        stft_reshaped = stft_features.reshape(stft_features.shape[0], -1)
        stft_normalized = self.scaler_stft.fit_transform(stft_reshaped)
        stft_features = stft_normalized.reshape(stft_features.shape)
        
        # æ ‡å‡†åŒ–æ—¶é—´åºåˆ—
        time_series_reshaped = time_series_data.reshape(time_series_data.shape[0], -1)
        time_series_normalized = self.scaler_time_series.fit_transform(time_series_reshaped)
        time_series_data = time_series_normalized.reshape(time_series_data.shape)
        
        # ä¿å­˜é¢„å¤„ç†å™¨
        with open(os.path.join(self.output_dir, 'scalers.pkl'), 'wb') as f:
            pickle.dump({
                'stft_scaler': self.scaler_stft,
                'time_series_scaler': self.scaler_time_series
            }, f)
        
        return stft_features, time_series_data, labels
    
    def _create_sliding_windows(self, data: np.ndarray, labels: np.ndarray, 
                               window_size: float = 5.0, overlap: float = 0.5) -> Tuple[List, List]:
        """åˆ›å»ºæ»‘åŠ¨çª—å£"""
        fs = 100
        window_samples = int(window_size * fs)
        stride_samples = int(window_samples * (1 - overlap))
        
        windows = []
        window_labels = []
        
        for start in range(0, len(data) - window_samples + 1, stride_samples):
            end = start + window_samples
            window_data = data[start:end]
            
            # çª—å£æ ‡ç­¾ï¼šå–ä¼—æ•°
            window_label_counts = np.bincount(labels[start:end])
            window_label = np.argmax(window_label_counts)
            
            windows.append(window_data)
            window_labels.append(window_label)
        
        return windows, window_labels
    
    def create_data_loaders(self, stft_features: np.ndarray, 
                           time_series_data: np.ndarray, 
                           labels: np.ndarray) -> Tuple[DataLoader, DataLoader]:
        """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
        # æ•°æ®åˆ†å‰²
        X_stft_train, X_stft_test, X_ts_train, X_ts_test, y_train, y_test = train_test_split(
            stft_features, time_series_data, labels,
            test_size=self.config['test_size'],
            random_state=42,
            stratify=labels
        )
        
        # åˆ›å»ºæ•°æ®é›†
        train_dataset = MultiModalDataset(X_stft_train, X_ts_train, y_train)
        test_dataset = MultiModalDataset(X_stft_test, X_ts_test, y_test)
        
        # ç±»åˆ«æƒé‡ï¼ˆå¤„ç†ä¸å¹³è¡¡æ•°æ®ï¼‰
        if self.config['use_class_weights']:
            class_counts = np.bincount(y_train)
            class_weights = 1.0 / class_counts
            sample_weights = class_weights[y_train]
            sampler = WeightedRandomSampler(
                weights=sample_weights,
                num_samples=len(sample_weights),
                replacement=True
            )
        else:
            sampler = None
        
        # è·å–GPUä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨å‚æ•°
        dataloader_params = self.config.get('dataloader_params', {})
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(
            train_dataset,
            batch_size=self.config['batch_size'],
            sampler=sampler,
            shuffle=(sampler is None),
            num_workers=dataloader_params.get('num_workers', 4),
            pin_memory=dataloader_params.get('pin_memory', True),
            persistent_workers=dataloader_params.get('persistent_workers', True),
            prefetch_factor=dataloader_params.get('prefetch_factor', 2),
            drop_last=dataloader_params.get('drop_last', False)
        )
        
        test_loader = DataLoader(
            test_dataset,
            batch_size=self.config['batch_size'],
            shuffle=False,
            num_workers=dataloader_params.get('num_workers', 4),
            pin_memory=dataloader_params.get('pin_memory', True),
            persistent_workers=dataloader_params.get('persistent_workers', True),
            prefetch_factor=dataloader_params.get('prefetch_factor', 2),
            drop_last=False  # æµ‹è¯•æ—¶ä¸ä¸¢å¼ƒæ•°æ®
        )
        
        return train_loader, test_loader
    
    def train_model(self, model: nn.Module, train_loader: DataLoader, 
                   test_loader: DataLoader, model_name: str) -> Dict:
        """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
        logger.info(f"å¼€å§‹è®­ç»ƒ {model_name} æ¨¡å‹...")
        
        # æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–ï¼ˆå¦‚æœæ”¯æŒï¼‰
        if self.config.get('compile_model', False) and hasattr(torch, 'compile'):
            try:
                model = torch.compile(model)
                logger.info("âœ… æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"âš ï¸ æ¨¡å‹ç¼–è¯‘å¤±è´¥: {e}")
        
        model = model.to(self.device)
        
        # å¤šGPUæ”¯æŒ
        if self.config.get('multi_gpu', False) and torch.cuda.device_count() > 1:
            model = nn.DataParallel(model)
            logger.info(f"âœ… å¤šGPUè®­ç»ƒå·²å¯ç”¨: {torch.cuda.device_count()} ä¸ªGPU")
        
        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        if self.config['use_class_weights']:
            # è®¡ç®—ç±»åˆ«æƒé‡
            all_labels = []
            for _, _, labels in train_loader:
                all_labels.extend(labels.numpy())
            class_counts = np.bincount(all_labels)
            class_weights = torch.FloatTensor(1.0 / class_counts).to(self.device)
        else:
            class_weights = None
        
        criterion = BehaviorClassificationLoss(
            alpha=1.0, gamma=2.0, class_weights=class_weights
        )
        
        optimizer = optim.AdamW(
            model.parameters(),
            lr=self.config['learning_rate'],
            weight_decay=1e-4
        )
        
        scheduler = CosineAnnealingLR(optimizer, T_max=self.config['num_epochs'])
        early_stopping = EarlyStopping(patience=self.config['patience'])
        
        # è®­ç»ƒå†å²
        history = {
            'train_loss': [], 'train_acc': [],
            'val_loss': [], 'val_acc': []
        }
        
        best_val_acc = 0.0
        
        for epoch in range(self.config['num_epochs']):
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            train_loss = 0.0
            train_correct = 0
            train_total = 0
            
            train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{self.config["num_epochs"]} [Train]')
            
            for batch_stft, batch_ts, batch_labels in train_pbar:
                batch_stft = batch_stft.to(self.device, non_blocking=True)
                batch_ts = batch_ts.to(self.device, non_blocking=True)
                batch_labels = batch_labels.to(self.device, non_blocking=True)
                
                optimizer.zero_grad()
                
                # æ··åˆç²¾åº¦è®­ç»ƒ
                if self.config.get('use_amp', False) and self.scaler is not None:
                    with torch.cuda.amp.autocast():
                        # å‰å‘ä¼ æ’­ï¼ˆæ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©è¾“å…¥ï¼‰
                        if model_name == 'fusion':
                            outputs = model(batch_stft, batch_ts)
                        elif model_name == 'cnn':
                            outputs = model(batch_stft)
                        elif model_name == 'transformer':
                            outputs = model(batch_ts)
                        
                        loss = criterion(outputs, batch_labels)
                    
                    # åå‘ä¼ æ’­ï¼ˆæ··åˆç²¾åº¦ï¼‰
                    self.scaler.scale(loss).backward()
                    
                    # æ¢¯åº¦è£å‰ª
                    self.scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    
                    # ä¼˜åŒ–å™¨æ­¥éª¤
                    self.scaler.step(optimizer)
                    self.scaler.update()
                else:
                    # æ ‡å‡†ç²¾åº¦è®­ç»ƒ
                    # å‰å‘ä¼ æ’­ï¼ˆæ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©è¾“å…¥ï¼‰
                    if model_name == 'fusion':
                        outputs = model(batch_stft, batch_ts)
                    elif model_name == 'cnn':
                        outputs = model(batch_stft)
                    elif model_name == 'transformer':
                        outputs = model(batch_ts)
                    
                    loss = criterion(outputs, batch_labels)
                    loss.backward()
                    
                    # æ¢¯åº¦è£å‰ª
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    
                    optimizer.step()
                
                # ç»Ÿè®¡
                train_loss += loss.item()
                _, predicted = outputs.max(1)
                train_total += batch_labels.size(0)
                train_correct += predicted.eq(batch_labels).sum().item()
                
                # æ›´æ–°è¿›åº¦æ¡
                train_pbar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Acc': f'{100.*train_correct/train_total:.2f}%'
                })
            
            # éªŒè¯é˜¶æ®µ
            model.eval()
            val_loss = 0.0
            val_correct = 0
            val_total = 0
            all_predictions = []
            all_true_labels = []
            
            with torch.no_grad():
                val_pbar = tqdm(test_loader, desc=f'Epoch {epoch+1}/{self.config["num_epochs"]} [Val]')
                
                for batch_stft, batch_ts, batch_labels in val_pbar:
                    batch_stft = batch_stft.to(self.device, non_blocking=True)
                    batch_ts = batch_ts.to(self.device, non_blocking=True)
                    batch_labels = batch_labels.to(self.device, non_blocking=True)
                    
                    # å‰å‘ä¼ æ’­ï¼ˆéªŒè¯æ—¶ä¹Ÿä½¿ç”¨æ··åˆç²¾åº¦ï¼‰
                    if self.config.get('use_amp', False) and self.scaler is not None:
                        with torch.cuda.amp.autocast():
                            if model_name == 'fusion':
                                outputs = model(batch_stft, batch_ts)
                            elif model_name == 'cnn':
                                outputs = model(batch_stft)
                            elif model_name == 'transformer':
                                outputs = model(batch_ts)
                            
                            loss = criterion(outputs, batch_labels)
                    else:
                        if model_name == 'fusion':
                            outputs = model(batch_stft, batch_ts)
                        elif model_name == 'cnn':
                            outputs = model(batch_stft)
                        elif model_name == 'transformer':
                            outputs = model(batch_ts)
                        
                        loss = criterion(outputs, batch_labels)
                    
                    val_loss += loss.item()
                    _, predicted = outputs.max(1)
                    val_total += batch_labels.size(0)
                    val_correct += predicted.eq(batch_labels).sum().item()
                    
                    all_predictions.extend(predicted.cpu().numpy())
                    all_true_labels.extend(batch_labels.cpu().numpy())
                    
                    val_pbar.set_postfix({
                        'Loss': f'{loss.item():.4f}',
                        'Acc': f'{100.*val_correct/val_total:.2f}%'
                    })
            
            # è®¡ç®—å¹³å‡å€¼
            avg_train_loss = train_loss / len(train_loader)
            avg_val_loss = val_loss / len(test_loader)
            train_acc = 100. * train_correct / train_total
            val_acc = 100. * val_correct / val_total
            
            # æ›´æ–°å†å²
            history['train_loss'].append(avg_train_loss)
            history['train_acc'].append(train_acc)
            history['val_loss'].append(avg_val_loss)
            history['val_acc'].append(val_acc)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step()
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                torch.save(model.state_dict(), 
                          os.path.join(self.output_dir, f'best_{model_name}_model.pth'))
            
            # æ—©åœæ£€æŸ¥
            if early_stopping(val_acc, model):
                logger.info(f"æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ")
                break
            
            # GPUå†…å­˜ç›‘æ§
            if torch.cuda.is_available():
                allocated = torch.cuda.memory_allocated() / (1024**3)
                reserved = torch.cuda.memory_reserved() / (1024**3)
                logger.info(f'GPUå†…å­˜: {allocated:.2f}GB / {reserved:.2f}GB (å·²ç”¨/ä¿ç•™)')
                
                # å¦‚æœå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œæ¸…ç†ç¼“å­˜
                if allocated > 0.8 * torch.cuda.get_device_properties(0).total_memory / (1024**3):
                    torch.cuda.empty_cache()
                    logger.info("ğŸ§¹ GPUå†…å­˜ç¼“å­˜å·²æ¸…ç†")
            
            # è®°å½•æ—¥å¿—
            logger.info(
                f'Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Train Acc={train_acc:.2f}%, '
                f'Val Loss={avg_val_loss:.4f}, Val Acc={val_acc:.2f}%'
            )
        
        # è®¡ç®—æœ€ç»ˆè¯„ä¼°æŒ‡æ ‡
        f1_macro = f1_score(all_true_labels, all_predictions, average='macro')
        f1_weighted = f1_score(all_true_labels, all_predictions, average='weighted')
        
        results = {
            'model_name': model_name,
            'best_val_acc': best_val_acc,
            'f1_macro': f1_macro,
            'f1_weighted': f1_weighted,
            'history': history,
            'predictions': all_predictions,
            'true_labels': all_true_labels
        }
        
        logger.info(f"{model_name} è®­ç»ƒå®Œæˆ:")
        logger.info(f"  æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
        logger.info(f"  F1-macro: {f1_macro:.4f}")
        logger.info(f"  F1-weighted: {f1_weighted:.4f}")
        
        return results
    
    def run_complete_pipeline(self) -> Dict:
        """è¿è¡Œå®Œæ•´çš„è®­ç»ƒæµæ°´çº¿"""
        logger.info("å¼€å§‹è¿è¡Œå®Œæ•´è®­ç»ƒæµæ°´çº¿...")
        
        # 1. æ•°æ®å‡†å¤‡
        stft_features, time_series_data, labels = self.prepare_data()
        
        # 2. åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, test_loader = self.create_data_loaders(
            stft_features, time_series_data, labels
        )
        
        # 3. è®­ç»ƒå¤šä¸ªæ¨¡å‹
        all_results = {}
        
        for model_type in self.config['model_types']:
            logger.info(f"\n{'='*50}")
            logger.info(f"è®­ç»ƒ {model_type.upper()} æ¨¡å‹")
            logger.info(f"{'='*50}")
            
            # åˆ›å»ºæ¨¡å‹
            if model_type == 'cnn':
                model = AdvancedBehaviorCNN(
                    input_shape=stft_features.shape[1:],
                    num_classes=4,
                    dropout=0.1
                )
            elif model_type == 'transformer':
                model = BehaviorTransformer(
                    input_dim=time_series_data.shape[-1],
                    d_model=512,
                    num_heads=8,
                    num_layers=6,
                    num_classes=4,
                    dropout=0.1
                )
            elif model_type == 'fusion':
                model = MultiModalFusionModel(
                    stft_input_shape=stft_features.shape[1:],
                    time_series_dim=time_series_data.shape[-1],
                    num_classes=4,
                    dropout=0.1
                )
            
            # æ‰“å°æ¨¡å‹æ‘˜è¦
            model_summary(model, {})
            
            # è®­ç»ƒæ¨¡å‹
            results = self.train_model(model, train_loader, test_loader, model_type)
            all_results[model_type] = results
        
        # 4. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self.generate_comprehensive_report(all_results)
        
        logger.info("å®Œæ•´è®­ç»ƒæµæ°´çº¿æ‰§è¡Œå®Œæˆ!")
        return all_results
    
    def generate_comprehensive_report(self, all_results: Dict):
        """ç”Ÿæˆç»¼åˆè¯„ä¼°æŠ¥å‘Š"""
        logger.info("ç”Ÿæˆç»¼åˆè¯„ä¼°æŠ¥å‘Š...")
        
        # 1. æ¨¡å‹æ€§èƒ½å¯¹æ¯”
        performance_df = pd.DataFrame([
            {
                'Model': results['model_name'],
                'Best_Val_Acc': results['best_val_acc'],
                'F1_Macro': results['f1_macro'],
                'F1_Weighted': results['f1_weighted']
            }
            for results in all_results.values()
        ])
        
        performance_df.to_csv(os.path.join(self.output_dir, 'model_comparison.csv'), index=False)
        
        # 2. å¯è§†åŒ–ç»“æœ
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ç»“æœ', fontsize=16)
        
        # è®­ç»ƒæŸå¤±æ›²çº¿
        for model_name, results in all_results.items():
            axes[0, 0].plot(results['history']['train_loss'], label=f'{model_name} Train')
            axes[0, 0].plot(results['history']['val_loss'], label=f'{model_name} Val')
        axes[0, 0].set_title('è®­ç»ƒæŸå¤±æ›²çº¿')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True)
        
        # è®­ç»ƒå‡†ç¡®ç‡æ›²çº¿
        for model_name, results in all_results.items():
            axes[0, 1].plot(results['history']['train_acc'], label=f'{model_name} Train')
            axes[0, 1].plot(results['history']['val_acc'], label=f'{model_name} Val')
        axes[0, 1].set_title('è®­ç»ƒå‡†ç¡®ç‡æ›²çº¿')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy (%)')
        axes[0, 1].legend()
        axes[0, 1].grid(True)
        
        # æ¨¡å‹æ€§èƒ½å¯¹æ¯”
        models = list(all_results.keys())
        val_accs = [all_results[m]['best_val_acc'] for m in models]
        f1_macros = [all_results[m]['f1_macro'] for m in models]
        
        x = np.arange(len(models))
        width = 0.35
        
        axes[0, 2].bar(x - width/2, val_accs, width, label='Validation Accuracy', alpha=0.8)
        axes[0, 2].bar(x + width/2, [f*100 for f in f1_macros], width, label='F1-Macro (Ã—100)', alpha=0.8)
        axes[0, 2].set_title('æ¨¡å‹æ€§èƒ½å¯¹æ¯”')
        axes[0, 2].set_ylabel('Score')
        axes[0, 2].set_xticks(x)
        axes[0, 2].set_xticklabels(models)
        axes[0, 2].legend()
        axes[0, 2].grid(True, alpha=0.3)
        
        # æ··æ·†çŸ©é˜µï¼ˆé€‰æ‹©æœ€ä½³æ¨¡å‹ï¼‰
        best_model = max(all_results.keys(), key=lambda k: all_results[k]['best_val_acc'])
        best_results = all_results[best_model]
        
        cm = confusion_matrix(best_results['true_labels'], best_results['predictions'])
        sns.heatmap(cm, annot=True, fmt='d', ax=axes[1, 0],
                   xticklabels=['é™æ¯', 'å’€åš¼', 'å’³å—½', 'åå’½'],
                   yticklabels=['é™æ¯', 'å’€åš¼', 'å’³å—½', 'åå’½'],
                   cmap='Blues')
        axes[1, 0].set_title(f'æ··æ·†çŸ©é˜µ - {best_model.upper()} (æœ€ä½³æ¨¡å‹)')
        
        # ç±»åˆ«F1åˆ†æ•°
        class_names = ['é™æ¯', 'å’€åš¼', 'å’³å—½', 'åå’½']
        class_f1s = f1_score(best_results['true_labels'], best_results['predictions'], average=None)
        
        axes[1, 1].bar(class_names, class_f1s, color=['skyblue', 'lightgreen', 'salmon', 'gold'])
        axes[1, 1].set_title(f'å„ç±»åˆ«F1åˆ†æ•° - {best_model.upper()}')
        axes[1, 1].set_ylabel('F1 Score')
        axes[1, 1].tick_params(axis='x', rotation=45)
        axes[1, 1].grid(True, alpha=0.3)
        
        # æ ‡ç­¾åˆ†å¸ƒ
        unique_labels, label_counts = np.unique(best_results['true_labels'], return_counts=True)
        axes[1, 2].pie(label_counts, labels=[class_names[i] for i in unique_labels], 
                      autopct='%1.1f%%', startangle=90)
        axes[1, 2].set_title('æ•°æ®é›†æ ‡ç­¾åˆ†å¸ƒ')
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, 'comprehensive_results.png'), 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. ç”Ÿæˆè¯¦ç»†åˆ†ç±»æŠ¥å‘Š
        report = classification_report(
            best_results['true_labels'], 
            best_results['predictions'],
            target_names=class_names,
            digits=4
        )
        
        with open(os.path.join(self.output_dir, 'classification_report.txt'), 'w', encoding='utf-8') as f:
            f.write(f"æœ€ä½³æ¨¡å‹: {best_model.upper()}\n")
            f.write("="*50 + "\n")
            f.write(report)
            f.write("\n\næ¨¡å‹æ€§èƒ½æ±‡æ€»:\n")
            f.write("-"*30 + "\n")
            for model_name, results in all_results.items():
                f.write(f"{model_name.upper()}:\n")
                f.write(f"  éªŒè¯å‡†ç¡®ç‡: {results['best_val_acc']:.2f}%\n")
                f.write(f"  F1-Macro: {results['f1_macro']:.4f}\n")
                f.write(f"  F1-Weighted: {results['f1_weighted']:.4f}\n\n")
        
        # 4. ä¿å­˜é…ç½®å’Œç»“æœ
        final_results = {
            'config': self.config,
            'performance_summary': performance_df.to_dict('records'),
            'best_model': best_model,
            'timestamp': datetime.now().isoformat()
        }
        
        with open(os.path.join(self.output_dir, 'experiment_summary.json'), 'w', encoding='utf-8') as f:
            json.dump(final_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ç»¼åˆè¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜åˆ°: {self.output_dir}")
        logger.info(f"æœ€ä½³æ¨¡å‹: {best_model.upper()} (éªŒè¯å‡†ç¡®ç‡: {all_results[best_model]['best_val_acc']:.2f}%)")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='åŸºäºè€³é“PPG&IMUçš„è¡Œä¸ºåˆ†ç±»å®Œæ•´è®­ç»ƒæµæ°´çº¿')
    parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--data_dir', type=str, default='./hyx_data', help='æ•°æ®ç›®å½•')
    parser.add_argument('--models', nargs='+', default=['cnn', 'transformer', 'fusion'], 
                       choices=['cnn', 'transformer', 'fusion'], help='è¦è®­ç»ƒçš„æ¨¡å‹ç±»å‹')
    parser.add_argument('--epochs', type=int, default=100, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=32, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--lr', type=float, default=1e-4, help='å­¦ä¹ ç‡')
    
    args = parser.parse_args()
    
    # åˆ›å»ºé…ç½®
    config = {
        'data_dir': args.data_dir,
        'model_types': args.models,
        'num_epochs': args.epochs,
        'batch_size': args.batch_size,
        'learning_rate': args.lr,
        'patience': 15,
        'test_size': 0.2,
        'use_class_weights': True,
        'augmentation': True,
        'feature_types': ['stft', 'time_series']
    }
    
    if args.config:
        with open(args.config, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
    
    print("="*60)
    print("åŸºäºè€³é“PPG&IMUçš„è¡Œä¸ºåˆ†ç±»ç³»ç»Ÿ")
    print("ç›®æ ‡ï¼šé™æ¯/å’€åš¼/å’³å—½/åå’½ å››åˆ†ç±»")
    print("="*60)
    
    # åˆå§‹åŒ–è®­ç»ƒæµæ°´çº¿
    pipeline = TrainingPipeline(args.config)
    
    # è¿è¡Œå®Œæ•´æµæ°´çº¿
    results = pipeline.run_complete_pipeline()
    
    print("\n" + "="*60)
    print("è®­ç»ƒæµæ°´çº¿æ‰§è¡Œå®Œæˆ!")
    print(f"ç»“æœä¿å­˜åœ¨: {pipeline.output_dir}")
    print("="*60)

if __name__ == "__main__":
    main()
