#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¸ºPython 3.13å®‰è£…PyTorch CPUç‰ˆæœ¬ï¼Œç„¶åå°è¯•GPUæ”¯æŒ
"""

import os
import sys
import subprocess
import json

def install_pytorch_cpu():
    """å®‰è£…PyTorch CPUç‰ˆæœ¬"""
    print("ğŸ“¦ å®‰è£…PyTorch CPUç‰ˆæœ¬...")
    
    try:
        cmd = [sys.executable, "-m", "pip", "install", "torch", "torchvision", "torchaudio", "--index-url", "https://download.pytorch.org/whl/cpu"]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
        
        if result.returncode == 0:
            print("âœ… PyTorch CPUç‰ˆæœ¬å®‰è£…æˆåŠŸ")
            return True
        else:
            print(f"âŒ å®‰è£…å¤±è´¥: {result.stderr}")
            return False
    except subprocess.TimeoutExpired:
        print("â° å®‰è£…è¶…æ—¶")
        return False
    except Exception as e:
        print(f"âŒ å¼‚å¸¸: {e}")
        return False

def install_other_dependencies():
    """å®‰è£…å…¶ä»–ä¾èµ–"""
    print("ğŸ“¦ å®‰è£…å…¶ä»–ä¾èµ–...")
    
    dependencies = [
        "numpy", "pandas", "matplotlib", "scipy", "scikit-learn", 
        "seaborn", "tqdm", "jupyter", "ipykernel"
    ]
    
    for dep in dependencies:
        try:
            cmd = [sys.executable, "-m", "pip", "install", dep]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                print(f"âœ… {dep} å®‰è£…æˆåŠŸ")
            else:
                print(f"âš ï¸ {dep} å®‰è£…å¤±è´¥: {result.stderr}")
        except Exception as e:
            print(f"âš ï¸ {dep} å®‰è£…å¼‚å¸¸: {e}")

def test_pytorch():
    """æµ‹è¯•PyTorchåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•PyTorchåŠŸèƒ½...")
    
    test_script = """
import torch
print(f'PyTorchç‰ˆæœ¬: {torch.__version__}')
print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')

if torch.cuda.is_available():
    print(f'CUDAç‰ˆæœ¬: {torch.version.cuda}')
    print(f'GPUæ•°é‡: {torch.cuda.device_count()}')
    print(f'GPUåç§°: {torch.cuda.get_device_name(0)}')
    
    # æµ‹è¯•GPUè®¡ç®—
    try:
        x = torch.randn(100, 100).cuda()
        y = torch.randn(100, 100).cuda()
        z = torch.matmul(x, y)
        print('âœ… GPUè®¡ç®—æµ‹è¯•æˆåŠŸ')
    except Exception as e:
        print(f'âŒ GPUè®¡ç®—æµ‹è¯•å¤±è´¥: {e}')
else:
    print('â„¹ï¸ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼')
    
    # æµ‹è¯•CPUè®¡ç®—
    try:
        x = torch.randn(100, 100)
        y = torch.randn(100, 100)
        z = torch.matmul(x, y)
        print('âœ… CPUè®¡ç®—æµ‹è¯•æˆåŠŸ')
    except Exception as e:
        print(f'âŒ CPUè®¡ç®—æµ‹è¯•å¤±è´¥: {e}')
"""
    
    try:
        exec(test_script)
        return True
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def create_config():
    """åˆ›å»ºé…ç½®æ–‡ä»¶"""
    print("ğŸ“ åˆ›å»ºé…ç½®æ–‡ä»¶...")
    
    # æ£€æµ‹GPUå¯ç”¨æ€§
    try:
        import torch
        use_gpu = torch.cuda.is_available()
        device_count = torch.cuda.device_count() if use_gpu else 1
    except:
        use_gpu = False
        device_count = 1
    
    config = {
        "data_dir": "./hyx_data",
        "batch_size": 16 if use_gpu else 8,
        "learning_rate": 1e-4,
        "num_epochs": 100,
        "patience": 15,
        "k_folds": 5,
        "test_size": 0.2,
        "model_types": ["cnn", "transformer", "fusion"],
        "use_class_weights": True,
        "augmentation": True,
        "feature_types": ["stft", "time_series"],
        "use_gpu": use_gpu,
        "device_id": 0,
        "use_amp": use_gpu,
        "compile_model": False,  # Python 3.13å¯èƒ½ä¸æ”¯æŒ
        "multi_gpu": False,
        "device_count": device_count,
        "dataloader_params": {
            "num_workers": 4 if use_gpu else 2,
            "pin_memory": use_gpu,
            "persistent_workers": use_gpu,
            "prefetch_factor": 2,
            "drop_last": True
        }
    }
    
    with open("python313_config.json", "w", encoding="utf-8") as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    
    print("âœ… é…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ")

def create_run_script():
    """åˆ›å»ºè¿è¡Œè„šæœ¬"""
    print("ğŸ“ åˆ›å»ºè¿è¡Œè„šæœ¬...")
    
    script_content = '''#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Python 3.13è®­ç»ƒè¿è¡Œè„šæœ¬
"""

import subprocess
import sys
import os

def main():
    print("ğŸš€ Python 3.13è®­ç»ƒ")
    print("="*50)
    
    # æ£€æŸ¥PyTorch
    try:
        import torch
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
            print(f"GPUåç§°: {torch.cuda.get_device_name(0)}")
            config_file = "python313_config.json"
            batch_size = "16"
            use_mixed_precision = "--mixed-precision"
        else:
            print("ä½¿ç”¨CPUæ¨¡å¼")
            config_file = "python313_config.json"
            batch_size = "8"
            use_mixed_precision = "--no-gpu"
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")
        return
    
    # è¿è¡Œè®­ç»ƒ
    cmd = [
        sys.executable,
        "run_behavior_classification.py",
        "--full-pipeline",
        "--config", config_file,
        use_mixed_precision,
        "--batch-size", batch_size
    ]
    
    print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    
    try:
        result = subprocess.run(cmd, check=True)
        print("âœ… è®­ç»ƒå®Œæˆ")
    except subprocess.CalledProcessError as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
    except Exception as e:
        print(f"âŒ å¼‚å¸¸: {e}")

if __name__ == "__main__":
    main()
'''
    
    with open("run_python313_training.py", "w", encoding="utf-8") as f:
        f.write(script_content)
    
    print("âœ… è¿è¡Œè„šæœ¬åˆ›å»ºå®Œæˆ")

def main():
    print("="*60)
    print("Python 3.13 PyTorchå®‰è£…å’Œé…ç½®")
    print("="*60)
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_version = f"{sys.version_info.major}.{sys.version_info.minor}"
    print(f"Pythonç‰ˆæœ¬: {python_version}")
    
    if python_version != "3.13":
        print("âš ï¸ æ­¤è„šæœ¬ä¸“ä¸ºPython 3.13è®¾è®¡")
    
    # å®‰è£…PyTorch CPUç‰ˆæœ¬
    if install_pytorch_cpu():
        # å®‰è£…å…¶ä»–ä¾èµ–
        install_other_dependencies()
        
        # æµ‹è¯•PyTorch
        if test_pytorch():
            print("\nğŸ‰ PyTorchå®‰è£…å’Œæµ‹è¯•æˆåŠŸï¼")
            
            # åˆ›å»ºé…ç½®æ–‡ä»¶
            create_config()
            
            # åˆ›å»ºè¿è¡Œè„šæœ¬
            create_run_script()
            
            print("\nğŸ“‹ ä½¿ç”¨æ–¹æ³•:")
            print("1. è¿è¡Œè®­ç»ƒ: python run_python313_training.py")
            print("2. æˆ–ç›´æ¥è¿è¡Œ: python run_behavior_classification.py --full-pipeline --config python313_config.json")
            
            return True
        else:
            print("\nâŒ PyTorchæµ‹è¯•å¤±è´¥")
            return False
    else:
        print("\nâŒ PyTorchå®‰è£…å¤±è´¥")
        return False

if __name__ == "__main__":
    main()
